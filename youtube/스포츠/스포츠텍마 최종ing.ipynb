{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # 웹 페이지 소스를 얻기 위한 패키지(기본 내장 패키지이다.)\n",
    "from bs4 import BeautifulSoup # 웹 페이지 소스를 얻기 위한 패키지, 더 간단히 얻을 수 있다는 장점이 있다고 한다.\n",
    "from datetime import datetime                                # (!pip install beautifulsoup4 으로 다운받을 수 있다.)\n",
    "import pandas as pd # 데이터를 처리하기 위한 가장 기본적인 패키지\n",
    "import time # 사이트를 불러올 때, 작업 지연시간을 지정해주기 위한 패키지이다. (사이트가 늦게 켜지면 에러가 발생하기 때문)\n",
    "import urllib.request #\n",
    "import json\n",
    "import re     \n",
    "import datetime as dt\n",
    "import os\n",
    "import glob\n",
    "from pandas import DataFrame\n",
    "from collections import Counter\n",
    "from konlpy.tag import Twitter\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from wordcloud import WordCloud\n",
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager as fm\n",
    "font_name = fm.FontProperties(fname = 'C:\\\\Windows\\\\Fonts\\\\malgun.ttf').get_name()\n",
    "plt.rc('font', family = font_name)\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= pd.read_csv('불용어사전(한글자).csv',encoding='cp949')\n",
    "stop_list = list(f)\n",
    "Unnamed = 'Unnamed: '+ str(len(stop_list)-1)\n",
    "stop_list.extend(['거','저','내','더','용','앞','만','도','앜','후','윤','분','늘','멀','줄','욬','수','번','안','이','제','요','안','뭐','더','전'])\n",
    "stop_words = set(stop_list)\n",
    "\n",
    "stop_words.remove(Unnamed)\n",
    "\n",
    "# stop_words\n",
    "\n",
    "# 단어 새로 추가했을 때에 사용!!!\n",
    "f = open('불용어사전(한글자).csv','w')\n",
    "for i in stop_words:\n",
    "    f.write(i+',')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유투브 채널 이름 입력하시오.회사원A\n"
     ]
    }
   ],
   "source": [
    "# # 인코딩 에러뜰때만 실행\n",
    "# youtube_channel = input(\"유투브 채널 이름 입력하시오.\")\n",
    "# date = pd.read_csv(youtube_channel+'/'+youtube_channel+'_info.csv',encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 인코딩 에러뜰때만 실행\n",
    "\n",
    "\n",
    "# date.to_csv(youtube_channel+'/'+youtube_channel+'_info.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유투브 채널 이름 입력하시오.JK 아트사커 온라인\n",
      "2020. 6. 3.\n",
      "2020. 5. 30.\n",
      "2020. 5. 24.\n",
      "2020. 5. 23.\n",
      "최초 공개: 2020. 5. 19.\n",
      "2020. 5. 15.\n",
      "2020. 5. 8.\n",
      "2020. 5. 2.\n",
      "2020. 4. 25.\n",
      "2020. 4. 18.\n",
      "최초 공개: 2020. 4. 14.\n",
      "2020. 4. 11.\n",
      "2020. 4. 10.\n",
      "2020. 4. 4.\n",
      "2020. 4. 3.\n",
      "최초 공개: 2020. 3. 13.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acorn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae8a3294a0e4afcb0bb1ef66a7c7f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "15",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1031368fa3db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mco_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mlikes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'like_num'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mstart_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mccc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     comment_final = pd.DataFrame(data = {'닉네임':you_id,\n\u001b[0;32m     30\u001b[0m                                 \u001b[1;34m'댓글'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mco_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4403\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"getitem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4404\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4405\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4406\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4407\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 15"
     ]
    }
   ],
   "source": [
    "# 파일 합치는 곳 (폴더 제목 입력)\n",
    "# 댓글에 날짜 추가!!!\n",
    "youtube_channel = input(\"유투브 채널 이름 입력하시오.\")\n",
    "date = pd.read_csv(youtube_channel+'/'+youtube_channel+'_info.csv')\n",
    "ccc = date[date['start_date'] >= '2020. 4. 1']['start_date']\n",
    "\n",
    "ccc\n",
    "# pd.read_csv('./Beauty/'+youtube_channel+'/comment/'+youtube_channel+'_comment_[i+1].csv')\n",
    "\n",
    "for i in ccc:\n",
    "     print(i)\n",
    "#     a = pd.read_csv(('./Beauty/'+youtube_channel+'/comment/'+youtube_channel+'_comment_{}.csv').format(i+1))['youtube'].values\n",
    "#     np.append(comment_date, a)     up_date = pd.read_csv(('./Beauty/'+youtube_channel+'/comment/'+youtube_channel+'_comment_{}.csv').format(i+1))\n",
    "#     comment_date.append(up_date)\n",
    "comment_date = []\n",
    "for i in range(len(ccc)):\n",
    "     print(i)\n",
    "     a = pd.read_csv((youtube_channel+'/comment/'+youtube_channel+'_comment_{}.csv').format(i+1))\n",
    "     comment_date.append(a)\n",
    "        \n",
    "comment_date[0]\n",
    "for i in tqdm_notebook(range(len(ccc))):\n",
    "    \n",
    "    df = comment_date[i]\n",
    "    you_id = df['youtube_id'].values\n",
    "    co_id = df['comment'].values\n",
    "    likes = df['like_num'].values\n",
    "    start_date = ccc[i]\n",
    "    comment_final = pd.DataFrame(data = {'닉네임':you_id,\n",
    "                                '댓글':co_id,\n",
    "                                '좋아요수':likes,\n",
    "                                '날짜':start_date})\n",
    "    comment_final.to_csv(youtube_channel+'/comment/'+ youtube_channel +'_comment_date{}.csv'.format(i+1),\n",
    "                        encoding='utf-8-sig',index=False)    \n",
    "\n",
    "\n",
    "path =  str(youtube_channel) + \"/comment\"\n",
    "path2 = str(youtube_channel) + '/result.csv'\n",
    "arg_youtube = str(youtube_channel) + \"*\"\n",
    "\n",
    "\n",
    "allFile_list = glob.glob(os.path.join(path,arg_youtube))\n",
    "#print(allFile_list)\n",
    "allData = []\n",
    "for file in allFile_list:\n",
    "    if 'date' in file:\n",
    "        # print(file)\n",
    "        df = pd.read_csv(file)\n",
    "        allData.append(df)\n",
    "    \n",
    "dataCombine = pd.concat(allData,axis =0, ignore_index = True)\n",
    "\n",
    "dataCombine.to_csv(path2, index = False)\n",
    "cdPath = str(youtube_channel) + '/result.csv'\n",
    "comment_data = pd.read_csv(cdPath)\n",
    "comment_data ##제대로 출력되는지 확인\n",
    "com_list = list(comment_data['댓글'])   ##제대로 출력되는지 확인\n",
    "# com_list   ##제대로 출력되는지 확인\n",
    "\n",
    "# ### 추출된 단어가 무슨 형태인지 파악\n",
    "# # for sentence in com_list:\n",
    "# #     morph = twitter.pos(sentence)\n",
    "# #     sentences_tag.append(morph)\n",
    "\n",
    "# 추출 단어들 저장\n",
    "\n",
    "def get_noun(comment_txt):\n",
    "    \n",
    "    twitter = Twitter()\n",
    "    noun_list = []\n",
    "    \n",
    "    if len(comment_txt) > 0:\n",
    "        twitter = twitter.pos(comment_txt, norm = True, stem = True)\n",
    "        for word, tag in twitter:\n",
    "            if tag in ['Noun']:\n",
    "                \n",
    "                if word not in stop_words:\n",
    "                    noun_list.append(word)\n",
    "                    \n",
    "    return noun_list\n",
    "\n",
    "def get_adj(comment_txt):\n",
    "\n",
    "    twitter = Twitter()\n",
    "    adj_list = []\n",
    "    \n",
    "    if len(comment_txt) > 0:\n",
    "        twitter = twitter.pos(comment_txt, norm = True, stem = True)\n",
    "        for word, tag in twitter:\n",
    "            if tag in ['Adjective']:\n",
    "                if word not in stop_words:\n",
    "                    adj_list.append(word)\n",
    "                    \n",
    "    return adj_list\n",
    "\n",
    "def get_verb(comment_txt):\n",
    "\n",
    "    twitter = Twitter()\n",
    "    verb_list = []\n",
    "    \n",
    "    if len(comment_txt) > 0:\n",
    "        twitter = twitter.pos(comment_txt, norm = True, stem = True)\n",
    "        for word, tag in twitter:\n",
    "            if tag in ['Verb']:\n",
    "                if word not in stop_words:\n",
    "                    verb_list.append(word)\n",
    "    return verb_list\n",
    "\n",
    "comment_list = []\n",
    "for i in range(len(comment_data)):\n",
    "    comment_list.append(comment_data['댓글'].iloc[i])\n",
    "    \n",
    "comment_result = []\n",
    "\n",
    "for i in comment_list:\n",
    "    comment_result.append(i)\n",
    "    \n",
    "comment_result = pd.DataFrame(comment_result, columns=[\"comment\"])\n",
    "    \n",
    "#cloud.to_file(youtube_channel+'/{}wordcloud.png'.format(youtube_channel)) # 해당폴더에 자동저장\n",
    "comment_result['noun'] = comment_result['comment'].apply(lambda x: get_noun(x))\n",
    "comment_result['adj'] = comment_result['comment'].apply(lambda x: get_adj(x))\n",
    "comment_result['verb'] = comment_result['comment'].apply(lambda x: get_verb(x))\n",
    "\n",
    "comment_result.to_csv(youtube_channel +'/{}token_result.csv'.format(youtube_channel),\n",
    "                                                                   index = False, encoding = 'utf-8-sig')\n",
    "\n",
    "\n",
    "twitter = Twitter()\n",
    "\n",
    "sentences_tag = []\n",
    "for sentence in tqdm_notebook(com_list):\n",
    "     morph = twitter.pos(sentence)\n",
    "     sentences_tag.append(morph)\n",
    "\n",
    "stop_words\n",
    "for sentence in comment_data:\n",
    "    morph = twitter.pos(sentence)\n",
    "    sentences_tag.append(morph)\n",
    "#     print(morph)\n",
    "#     print('-'*30)\n",
    "\n",
    "# print(sentences_tag)\n",
    "# print(len(sentences_tag))\n",
    "# print('\\n'*3)\n",
    "\n",
    "noun_adj_list = []\n",
    "for sentence1 in sentences_tag:\n",
    "    for word, tag in sentence1:\n",
    "        if tag in ['Noun','Adjective','verb']:\n",
    "            if word not in stop_words:\n",
    "                noun_adj_list.append(word)            \n",
    "\n",
    "counts = Counter(noun_adj_list)\n",
    "select_data = counts.most_common(50)\n",
    "\n",
    "\n",
    "wc = WordCloud(font_path='NanumGothic.ttf',max_font_size=150,background_color='white' ,width=800, height=600)\n",
    "    \n",
    "print(dict(select_data))\n",
    "cloud = wc.generate_from_frequencies(dict(select_data))\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.axis('off')\n",
    "plt.imshow(cloud,interpolation='bilinear')\n",
    "plt.show()\n",
    "cloud.to_file(youtube_channel+'/{}wordcloud.png'.format(youtube_channel)) # 해당폴더에 자동저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
